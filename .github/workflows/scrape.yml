name: scrape

on:
  workflow_dispatch:
  schedule:
    - cron: "0 1 * * *" # daily at 01:00 UTC

jobs:
  scrape:
    runs-on: ubuntu-24.04
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET 6 SDK
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: 6.0.x

      - name: Restore packages
        working-directory: src
        run: dotnet restore

      - name: Build (Debug)
        working-directory: src
        run: dotnet build -c Debug

      - name: Install Playwright Chromium
        working-directory: src
        shell: pwsh
        run: bin/Debug/net6.0/playwright.ps1 install chromium

      - name: Verify Urls.txt exists
        working-directory: src
        run: |
          set -e
          test -f Urls.txt && echo "Found src/Urls.txt" || (echo "src/Urls.txt missing!" && exit 1)
          head -n 3 Urls.txt || true

      - name: Stage runtime inputs (Urls.txt + appsettings.json) to bin/Debug/net6.0
        working-directory: src
        run: |
          RUNTIME_DIR="bin/Debug/net6.0"
          mkdir -p "$RUNTIME_DIR"

          # One-line JSON (strict parser)
          printf '{"GEOLOCATION_LAT":"-37.73953","GEOLOCATION_LONG":"176.09528"}' > appsettings.json
          echo "appsettings.json content:"
          cat appsettings.json

          cp Urls.txt "$RUNTIME_DIR/Urls.txt"
          cp appsettings.json "$RUNTIME_DIR/appsettings.json"
          echo "Runtime dir contents:"
          ls -la "$RUNTIME_DIR"

      # Run under Xvfb; never fail the job here â€” we save the exit code and logs
      - name: Run scraper (Debug, no rebuild) under xvfb
        working-directory: src
        timeout-minutes: 30
        run: |
          set +e
          xvfb-run -a dotnet run -c Debug --no-build \
            >  ../out.stdout.txt \
            2> ../out.stderr.txt
          code=$?
          echo "$code" > ../exit.code
          echo "Scraper exit code: $code"
          # Do not fail the step regardless of scraper result
          exit 0

      # Always upload logs & inputs, even if previous step crashed
      - name: Upload outputs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-outputs
          path: |
            out.stdout.txt
            out.stderr.txt
            exit.code
            src/Urls.txt
            src/appsettings.json
            src/bin/Debug/net6.0/appsettings.json
            src/bin/Debug/net6.0/Urls.txt
          if-no-files-found: warn
