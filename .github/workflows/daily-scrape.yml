name: Daily Pak'nSave Scrape → Google Sheets

on:
  schedule:
    - cron: "0 18 * * *"   # 6:00 AM NZST / 7:00 AM NZDT
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '6.0.x'

      - name: Install Playwright CLI
        run: dotnet tool install --global Microsoft.Playwright.CLI

      - name: Add Playwright CLI to PATH
        run: echo "$HOME/.dotnet/tools" >> $GITHUB_PATH

      - name: Restore & Build
        run: |
          dotnet restore src/PakScraper.csproj
          dotnet build src/PakScraper.csproj -c Release

      - name: Install Chromium for Playwright
        working-directory: src/bin/Release/net6.0
        run: pwsh ./playwright.ps1 install chromium

      # ⬇️ Start a virtual X server and export DISPLAY for this job
      - name: Start Xvfb
        run: |
          sudo apt-get update
          sudo apt-get install -y xvfb
          Xvfb :99 -screen 0 1280x720x24 > /dev/null 2>&1 &
          echo "DISPLAY=:99" >> $GITHUB_ENV

      # ⬇️ Run the scraper normally; Playwright will see DISPLAY and be happy
      - name: Run the scraper (capture JSON)
        run: |
          dotnet run --project src/PakScraper.csproj > out.json
          echo "Wrote scraper output to out.json"

      - name: Install Python deps for Sheets
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install google-api-python-client pandas

      - name: Push to Google Sheets
        env:
          GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }}  # service account JSON (entire file)
          SHEET_ID: ${{ secrets.SHEET_ID }}      # spreadsheet ID
          SHEET_TAB: ${{ secrets.SHEET_TAB }}    # e.g., Sheet1
        run: |
          python3 - << 'PY'
          import os, json, sys, datetime
          import pandas as pd
          from google.oauth2.service_account import Credentials
          from googleapiclient.discovery import build

          # --- Load output ---
          try:
            raw = open("out.json","r",encoding="utf-8").read().strip()
          except FileNotFoundError:
            print("out.json not found", file=sys.stderr)
            sys.exit(1)

          data = []
          if raw:
            try:
              j = json.loads(raw)
              data = j if isinstance(j, list) else [j]
            except json.JSONDecodeError:
              for line in raw.splitlines():
                line=line.strip()
                if not line: continue
                try:
                  data.append(json.loads(line))
                except Exception:
                  pass

          if not data:
            print("No JSON records parsed from scraper output.", file=sys.stderr)
            sys.exit(0)

          df = pd.json_normalize(data)
          now = datetime.datetime.utcnow().isoformat(timespec="seconds") + "Z"
          if "ingested_at" not in df.columns:
            df["ingested_at"] = now
          cols = list(df.columns)
          df = df[cols]

          creds = Credentials.from_service_account_info(
            json.loads(os.environ["GCP_SA_KEY"]),
            scopes=["https://www.googleapis.com/auth/spreadsheets"]
          )
          svc = build("sheets","v4",credentials=creds)

          values = [cols] + df.fillna("").astype(str).values.tolist()
          read = svc.spreadsheets().values().get(
            spreadsheetId=os.environ["SHEET_ID"],
            range=f"{os.environ.get('SHEET_TAB','Sheet1')}!A1:A1"
          ).execute()
          has_any = 'values' in read
          if has_any:
            values = values[1:]

          if values:
            svc.spreadsheets().values().append(
              spreadsheetId=os.environ["SHEET_ID"],
              range=f"{os.environ.get('SHEET_TAB','Sheet1')}!A1",
              valueInputOption="RAW",
              insertDataOption="INSERT_ROWS",
              body={"values": values}
            ).execute()
          print(f"Appended {len(values)} row(s)")
          PY
